# LLM Privacy

This is a small demo project with a backend that uses the kalosm Rust crate to run an LLM locally and a frontend that supports chat with this LLM.

## How to Run

How to run locally:

- To run the front end, `cd client`, then `npm install`, then `npm start`.
- To run the back end, `cd server`, then `cargo run`.
